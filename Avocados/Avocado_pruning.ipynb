{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avocado_pruning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApyQTRzMcUCB",
        "colab_type": "text"
      },
      "source": [
        "# Prepare tensorflow-model-optimization for pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIe8xTeVtIWd",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWNPotwubYRu",
        "colab_type": "code",
        "outputId": "7d04820e-d6f3-448d-943e-26a2c84fadbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip uninstall -y tf-nightly\n",
        "! pip install -U tensorflow-gpu==1.14.0\n",
        "\n",
        "! pip install tensorflow-model-optimization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.0:\n",
            "  Successfully uninstalled tensorflow-1.15.0\n",
            "\u001b[33mWARNING: Skipping tf-nightly as it is not installed.\u001b[0m\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 27.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.27.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (45.2.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.8.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n",
            "Collecting tensorflow-model-optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/c4/4c3d011e432bd9c19f0323f7da7d3f783402615e4c3b5a98416c7da9cb05/tensorflow_model_optimization-0.2.1-py2.py3-none-any.whl (93kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.12.0)\n",
            "Collecting enum34~=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/df/6e/46a0304561a07bda942c4283b67228d5b87d1ebd1189c866ede4b4cd6a0a/enum34-1.1.9-py3-none-any.whl\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.17.5)\n",
            "Installing collected packages: enum34, tensorflow-model-optimization\n",
            "Successfully installed enum34-1.1.9 tensorflow-model-optimization-0.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBfBLXz1mCNV",
        "colab_type": "code",
        "outputId": "cec649e4-c1ac-4539-cec6-933ece94b0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "%load_ext tensorboard\n",
        "import tensorboard\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mk1dYHpbicZ",
        "colab_type": "text"
      },
      "source": [
        "#Download dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu64LC4Wm1oc",
        "colab_type": "code",
        "outputId": "f72e2294-cec7-4d32-8fc3-e82701d8b120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWT-iIqSb_46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://drive.google.com/open?id=1Wz2xqSZSjLDzXXTLdkf6zyTUUcBopn3i\n",
        "download = drive.CreateFile({'id': '1Wz2xqSZSjLDzXXTLdkf6zyTUUcBopn3i'})\n",
        "download.GetContentFile('avocado_dataset_w64.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRDlBcilciuY",
        "colab_type": "text"
      },
      "source": [
        "# Read Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRqt2u-MVfZ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "a10ed636-fc8d-4eb2-d350-1ba6d58e794f"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "from operator import truediv\n",
        "import h5py\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, cohen_kappa_score, confusion_matrix\n",
        "\n",
        "import tensorboard\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Data augmentation functions\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "def add_rotation_flip(x, y):\n",
        "\n",
        "    x = np.reshape(x, (x.shape[0], x.shape[1], x.shape[2], x.shape[3], 1))\n",
        "\n",
        "    # Flip horizontally\n",
        "    x_h = np.flip(x[:, :, :, :, :], 1)\n",
        "    # Flip vertically\n",
        "    x_v = np.flip(x[:, :, :, :, :], 2)\n",
        "    # Flip horizontally and vertically\n",
        "    x_hv = np.flip(x_h[:, :, :, :, :], 2)\n",
        "\n",
        "    # Concatenate\n",
        "    x = np.concatenate((x, x_h, x_v, x_hv))\n",
        "    y = np.concatenate((y, y, y, y))\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "LOAD HDF5 FILE\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "hdf5_file = h5py.File('avocado_dataset_w64.hdf5', \"r\")\n",
        "train_x = np.array(hdf5_file[\"train_img\"][...])\n",
        "train_y = np.array(hdf5_file[\"train_labels\"][...])\n",
        "\n",
        "# Average consecutive bands\n",
        "img2 = np.zeros((train_x.shape[0], int(train_x.shape[1]/2), int(train_x.shape[2]/2), int(train_x.shape[3] / 2)))\n",
        "for n in range(0, train_x.shape[0]):\n",
        "    xt = cv2.resize(np.float32(train_x[n, :, :, :]), (32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "    for i in range(0, train_x.shape[3], 2):\n",
        "        img2[n, :, :, int(i / 2)] = (xt[:, :, i] + xt[:, :, i + 1]) / 2.\n",
        "\n",
        "train_x = img2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3wrK8dNe-T7",
        "colab_type": "code",
        "outputId": "8e572b20-9ecd-4f28-edbf-e12b3bfa0460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_x, train_y = add_rotation_flip(train_x, train_y)\n",
        "print(train_x.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(964, 32, 32, 150, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvx55MBgcrZJ",
        "colab_type": "text"
      },
      "source": [
        "# Trained pruned network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f2xU6uWWAuz",
        "colab_type": "code",
        "outputId": "5836b70d-0a7a-4cdb-d47e-a6c74b031050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "data = 'AVOCADO'\n",
        "loaded_model = tf.keras.models.load_model(\"weights-hyper3dnet\" + data + str(1) + \"-best_3layers_4filters.h5\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psE2WVq7DItg",
        "colab_type": "code",
        "outputId": "874feb88-05bb-4666-bd32-5a12e4ed5535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "epochs = 8\n",
        "batch_size = 16;\n",
        "num_train_samples = train_x.shape[0]\n",
        "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
        "print(end_step)\n",
        "\n",
        "new_pruning_params = {\n",
        "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.5,\n",
        "                                                   final_sparsity=0.9,\n",
        "                                                   begin_step=0,\n",
        "                                                   end_step=end_step,\n",
        "                                                   frequency=100)\n",
        "}\n",
        "\n",
        "new_pruned_model = sparsity.prune_low_magnitude(loaded_model, **new_pruning_params)\n",
        "new_pruned_model.summary()\n",
        "\n",
        "new_pruned_model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer='adadelta',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "488\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 32, 32, 150, 1)]  0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv3d_3 (None, 32, 32, 150, 1)    93        \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_reshape_ (None, 32, 32, 150)       1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_separabl (None, 32, 32, 96)        32648     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_batch_no (None, 32, 32, 96)        385       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_activati (None, 32, 32, 96)        1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_separabl (None, 16, 16, 96)        19394     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_batch_no (None, 16, 16, 96)        385       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_activati (None, 16, 16, 96)        1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_separabl (None, 8, 8, 96)          19394     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_activati (None, 8, 8, 96)          1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_global_a (None, 96)                1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_fc1 (Pru (None, 1)                 195       \n",
            "=================================================================\n",
            "Total params: 72,499\n",
            "Trainable params: 39,125\n",
            "Non-trainable params: 33,374\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjYBXiSTtaDt",
        "colab_type": "code",
        "outputId": "1708f26d-f0d0-4c45-8e5c-9b5524934afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "windowSize = train_x.shape[1]\n",
        "classes = 2\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
        "cvoa = []\n",
        "cvaa = []\n",
        "cvka = []\n",
        "cvpre = []\n",
        "cvrec = []\n",
        "cvf1 = []\n",
        "cva1 = []\n",
        "cva2 = []\n",
        "cva3 = []\n",
        "\n",
        "\n",
        "data = 'AVOCADO'\n",
        "ntrain = 1\n",
        "for train, test in kfold.split(train_x, train_y):\n",
        "\n",
        "    ytrain = train_y[train]\n",
        "    ytest = train_y[test]\n",
        "\n",
        "    xtrain = train_x[train]\n",
        "    xtest = train_x[test]\n",
        "\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    PRUNING\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    new_pruning_params = {\n",
        "          'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.10,\n",
        "                                                      final_sparsity=0.20,\n",
        "                                                      begin_step=0,\n",
        "                                                      end_step=end_step,\n",
        "                                                      frequency=100)\n",
        "    }\n",
        "\n",
        "    loaded_model.load_weights(\"weights-hyper3dnet\" + data + str(ntrain) + \"-best_3layers_4filters.h5\")\n",
        "\n",
        "    new_pruned_model = sparsity.prune_low_magnitude(loaded_model, **new_pruning_params)\n",
        "\n",
        "    new_pruned_model.compile(\n",
        "        loss=tf.keras.losses.binary_crossentropy,\n",
        "        optimizer='adadelta',\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    # checkpoint\n",
        "    filepath = \"pruned-weights-hyper3dnet\" + data + str(ntrain) + \"-best_3layers_4filters.h5\"\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "    callbacks_list = [checkpoint, sparsity.UpdatePruningStep()]\n",
        "\n",
        "    # Train model on dataset\n",
        "    print(data + \": Training\" + str(ntrain) + \"begins...\")\n",
        "    history = new_pruned_model.fit(x=xtrain, y=ytrain, validation_data=(xtest, ytest),\n",
        "                        batch_size=16, epochs=epochs, callbacks=callbacks_list)\n",
        "    \n",
        "    new_pruned_model.save_weights(\"pruned-weights-hyper3dnet\" + data + str(ntrain) + \"-best_3layers_4filters.h5\")\n",
        "    # new_pruned_model.compile(\n",
        "    #     loss=tf.keras.losses.binary_crossentropy,\n",
        "    #     optimizer='adadelta',\n",
        "    #     metrics=['accuracy'])\n",
        "    ypred = new_pruned_model.predict(xtest)\n",
        "    ypred = ypred.round()\n",
        "    print(np.sum(ypred.transpose()==ytest)/len(ytest))\n",
        "    \n",
        "    ntrain += 1\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AVOCADO: Training1begins...\n",
            "Train on 867 samples, validate on 97 samples\n",
            "Epoch 1/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 3.0632e-05 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned-weights-hyper3dnetAVOCADO1-best_3layers_4filters.h5\n",
            "867/867 [==============================] - 8s 9ms/sample - loss: 3.0619e-05 - acc: 1.0000 - val_loss: 2.0785e-05 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 4.8414e-06 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 4.8252e-06 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 2.6225e-05 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 2.6136e-05 - acc: 1.0000 - val_loss: 1.7274e-04 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 4.1638e-04 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 4.2784e-04 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 0.9897\n",
            "Epoch 5/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 6.6606e-04 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 6.6376e-04 - acc: 1.0000 - val_loss: 5.8967e-04 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 3.8619e-04 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 3.8731e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.9657e-04 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 1.9598e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.4748e-04 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 1.4703e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training2begins...\n",
            "Train on 867 samples, validate on 97 samples\n",
            "Epoch 1/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned-weights-hyper3dnetAVOCADO2-best_3layers_4filters.h5\n",
            "867/867 [==============================] - 8s 9ms/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9977\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 5s 5ms/sample - loss: 0.0063 - acc: 0.9977 - val_loss: 0.0038 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9988\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 0.0025 - acc: 0.9988 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9977\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 0.0052 - acc: 0.9977 - val_loss: 0.0030 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9977\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 0.0101 - acc: 0.9977 - val_loss: 0.0148 - val_acc: 0.9897\n",
            "Epoch 7/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9954\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 5s 5ms/sample - loss: 0.0092 - acc: 0.9954 - val_loss: 0.0092 - val_acc: 0.9897\n",
            "Epoch 8/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9965\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 0.0089 - acc: 0.9965 - val_loss: 0.0040 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training3begins...\n",
            "Train on 867 samples, validate on 97 samples\n",
            "Epoch 1/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.9254e-04 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 0.96907, saving model to pruned-weights-hyper3dnetAVOCADO3-best_3layers_4filters.h5\n",
            "867/867 [==============================] - 7s 8ms/sample - loss: 1.9212e-04 - acc: 1.0000 - val_loss: 0.0413 - val_acc: 0.9691\n",
            "Epoch 2/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.4275e-04 - acc: 1.0000\n",
            "Epoch 00002: val_acc improved from 0.96907 to 0.98969, saving model to pruned-weights-hyper3dnetAVOCADO3-best_3layers_4filters.h5\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 1.4226e-04 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 0.9897\n",
            "Epoch 3/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 0.98969\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9897\n",
            "Epoch 4/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 3.4607e-04 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 0.98969\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 3.4488e-04 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 0.9897\n",
            "Epoch 5/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 3.2219e-04 - acc: 1.0000\n",
            "Epoch 00005: val_acc improved from 0.98969 to 1.00000, saving model to pruned-weights-hyper3dnetAVOCADO3-best_3layers_4filters.h5\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 3.2108e-04 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.0033e-04 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 1.0061e-04 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.3678e-04 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 1.3636e-04 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 8.0082e-05 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 7.9805e-05 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training4begins...\n",
            "Train on 867 samples, validate on 97 samples\n",
            "Epoch 1/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.9212e-05 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned-weights-hyper3dnetAVOCADO4-best_3layers_4filters.h5\n",
            "867/867 [==============================] - 7s 8ms/sample - loss: 1.9250e-05 - acc: 1.0000 - val_loss: 9.1768e-04 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 2.7559e-05 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 2.8151e-05 - acc: 1.0000 - val_loss: 2.3289e-04 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 4.1315e-05 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 4.1235e-05 - acc: 1.0000 - val_loss: 2.2983e-04 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.4324e-05 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 1.5717e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.9128e-05 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 2.3074e-05 - acc: 1.0000 - val_loss: 8.7371e-04 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 6.2542e-05 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 6.2356e-05 - acc: 1.0000 - val_loss: 2.7296e-04 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 8.4052e-05 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 8.3773e-05 - acc: 1.0000 - val_loss: 3.2842e-04 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.6448e-04 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 4s 5ms/sample - loss: 4.5863e-04 - acc: 1.0000 - val_loss: 3.6538e-04 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training5begins...\n",
            "Train on 868 samples, validate on 96 samples\n",
            "Epoch 1/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9919\n",
            "Epoch 00001: val_acc improved from -inf to 0.98958, saving model to pruned-weights-hyper3dnetAVOCADO5-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 7s 8ms/sample - loss: 0.0126 - acc: 0.9919 - val_loss: 0.0132 - val_acc: 0.9896\n",
            "Epoch 2/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9942\n",
            "Epoch 00002: val_acc did not improve from 0.98958\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0161 - acc: 0.9942 - val_loss: 0.3148 - val_acc: 0.8750\n",
            "Epoch 3/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9896\n",
            "Epoch 00003: val_acc did not improve from 0.98958\n",
            "868/868 [==============================] - 5s 5ms/sample - loss: 0.0260 - acc: 0.9885 - val_loss: 0.0907 - val_acc: 0.9792\n",
            "Epoch 4/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9931\n",
            "Epoch 00004: val_acc improved from 0.98958 to 1.00000, saving model to pruned-weights-hyper3dnetAVOCADO5-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 5s 6ms/sample - loss: 0.0172 - acc: 0.9931 - val_loss: 0.0107 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9873\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 5s 5ms/sample - loss: 0.0254 - acc: 0.9873 - val_loss: 0.0128 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9896\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0285 - acc: 0.9896 - val_loss: 0.1333 - val_acc: 0.9583\n",
            "Epoch 7/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9896\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0247 - acc: 0.9896 - val_loss: 0.0722 - val_acc: 0.9792\n",
            "Epoch 8/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9884\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0317 - acc: 0.9885 - val_loss: 0.0322 - val_acc: 0.9792\n",
            "0.9791666666666666\n",
            "AVOCADO: Training6begins...\n",
            "Train on 868 samples, validate on 96 samples\n",
            "Epoch 1/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 7.8139e-04 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned-weights-hyper3dnetAVOCADO6-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 7s 8ms/sample - loss: 7.7781e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0543 - val_acc: 0.9688\n",
            "Epoch 3/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 9.3506e-04 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 9.3163e-04 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 0.9896\n",
            "Epoch 7/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 0.9896\n",
            "Epoch 8/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 9.0988e-04 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 9.1118e-04 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training7begins...\n",
            "Train on 868 samples, validate on 96 samples\n",
            "Epoch 1/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9954\n",
            "Epoch 00001: val_acc improved from -inf to 0.57292, saving model to pruned-weights-hyper3dnetAVOCADO7-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 7s 8ms/sample - loss: 0.0144 - acc: 0.9942 - val_loss: 3.5951 - val_acc: 0.5729\n",
            "Epoch 2/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9988\n",
            "Epoch 00002: val_acc improved from 0.57292 to 0.91667, saving model to pruned-weights-hyper3dnetAVOCADO7-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0042 - acc: 0.9988 - val_loss: 0.4862 - val_acc: 0.9167\n",
            "Epoch 3/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9988\n",
            "Epoch 00003: val_acc improved from 0.91667 to 0.95833, saving model to pruned-weights-hyper3dnetAVOCADO7-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0091 - acc: 0.9988 - val_loss: 0.1087 - val_acc: 0.9583\n",
            "Epoch 4/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9965\n",
            "Epoch 00004: val_acc improved from 0.95833 to 0.97917, saving model to pruned-weights-hyper3dnetAVOCADO7-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0081 - acc: 0.9965 - val_loss: 0.0248 - val_acc: 0.9792\n",
            "Epoch 5/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9988\n",
            "Epoch 00005: val_acc improved from 0.97917 to 1.00000, saving model to pruned-weights-hyper3dnetAVOCADO7-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0028 - acc: 0.9988 - val_loss: 0.0072 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9965\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0090 - acc: 0.9965 - val_loss: 0.0102 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9942\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0125 - acc: 0.9942 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9977\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0117 - acc: 0.9977 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training8begins...\n",
            "Train on 868 samples, validate on 96 samples\n",
            "Epoch 1/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 2.5199e-04 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned-weights-hyper3dnetAVOCADO8-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 8s 9ms/sample - loss: 2.5163e-04 - acc: 1.0000 - val_loss: 9.1919e-04 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 3.3865e-04 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 5.0029e-04 - acc: 1.0000 - val_loss: 0.1946 - val_acc: 0.9271\n",
            "Epoch 3/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 4.0544e-04 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 4.0400e-04 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9896\n",
            "Epoch 4/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 4.9971e-04 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 4.9741e-04 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 1.5646e-04 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 1.5664e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1229 - val_acc: 0.9479\n",
            "Epoch 7/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 3.0664e-04 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 3.0543e-04 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training9begins...\n",
            "Train on 868 samples, validate on 96 samples\n",
            "Epoch 1/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 2.4881e-05 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned-weights-hyper3dnetAVOCADO9-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 7s 8ms/sample - loss: 5.5005e-05 - acc: 1.0000 - val_loss: 3.1499e-05 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 4.4479e-06 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 4.4274e-06 - acc: 1.0000 - val_loss: 2.2453e-05 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 1.9884e-04 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 5.9761e-04 - acc: 1.0000 - val_loss: 1.3882e-05 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9988\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 0.0016 - acc: 0.9988 - val_loss: 3.7904e-05 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 1.5118e-04 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 1.5055e-04 - acc: 1.0000 - val_loss: 2.5160e-05 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 1.7026e-04 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 1.6984e-04 - acc: 1.0000 - val_loss: 5.7858e-05 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 3.0177e-05 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 1.4451e-04 - acc: 1.0000 - val_loss: 4.0869e-05 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 3.1997e-04 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 3.3333e-04 - acc: 1.0000 - val_loss: 3.1910e-05 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training10begins...\n",
            "Train on 868 samples, validate on 96 samples\n",
            "Epoch 1/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 1.9768e-05 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned-weights-hyper3dnetAVOCADO10-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 7s 8ms/sample - loss: 1.9677e-05 - acc: 1.0000 - val_loss: 5.7491e-04 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 4.4707e-06 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 4.4577e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 2.9963e-06 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 3.1226e-06 - acc: 1.0000 - val_loss: 6.7158e-04 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 7.7709e-06 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 8.0677e-06 - acc: 1.0000 - val_loss: 3.0780e-04 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 2.8280e-05 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 2.8166e-05 - acc: 1.0000 - val_loss: 4.3932e-04 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 3.1445e-05 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 3.1309e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 1.1700e-04 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 1.1868e-04 - acc: 1.0000 - val_loss: 5.8853e-04 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 3.1069e-05 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 3.0926e-05 - acc: 1.0000 - val_loss: 3.0057e-04 - val_acc: 1.0000\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSmz9PSRTvPP",
        "colab_type": "code",
        "outputId": "5fc8bc23-a556-41d6-90ae-e2e19f61022a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "new_pruned_model.load_weights(\"pruned-weights-hyper3dnet\" + data + str(2) + \"-best_3layers_4filters.h5\")\n",
        "final_model = sparsity.strip_pruning(new_pruned_model)\n",
        "final_model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 32, 32, 150, 1)]  0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 32, 32, 150, 1)    46        \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 32, 32, 150)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_7 (Separabl (None, 32, 32, 96)        18246     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_8 (Separabl (None, 16, 16, 96)        10176     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_9 (Separabl (None, 8, 8, 96)          10176     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 8, 8, 96)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 1)                 97        \n",
            "=================================================================\n",
            "Total params: 39,509\n",
            "Trainable params: 39,125\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8drkv1mK1CUb",
        "colab_type": "code",
        "outputId": "7806d269-7cb6-4fdb-c42e-91c81ec86e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "import numpy as np\n",
        "for i, w in enumerate(final_model.get_weights()):\n",
        "    print(\n",
        "        \"{} -- Total:{}, Zeros: {:.4f}%\".format(\n",
        "            final_model.weights[i].name, w.size, np.sum(w == 0) / w.size * 100\n",
        "        )\n",
        "    )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv3d_3/kernel:0 -- Total:45, Zeros: 20.0000%\n",
            "conv3d_3/bias:0 -- Total:1, Zeros: 0.0000%\n",
            "separable_conv2d_7/depthwise_kernel:0 -- Total:3750, Zeros: 0.0000%\n",
            "separable_conv2d_7/pointwise_kernel:0 -- Total:14400, Zeros: 19.9444%\n",
            "separable_conv2d_7/bias:0 -- Total:96, Zeros: 0.0000%\n",
            "batch_normalization_5/gamma:0 -- Total:96, Zeros: 0.0000%\n",
            "batch_normalization_5/beta:0 -- Total:96, Zeros: 0.0000%\n",
            "batch_normalization_5/moving_mean:0 -- Total:96, Zeros: 0.0000%\n",
            "batch_normalization_5/moving_variance:0 -- Total:96, Zeros: 0.0000%\n",
            "separable_conv2d_8/depthwise_kernel:0 -- Total:864, Zeros: 0.0000%\n",
            "separable_conv2d_8/pointwise_kernel:0 -- Total:9216, Zeros: 19.9436%\n",
            "separable_conv2d_8/bias:0 -- Total:96, Zeros: 0.0000%\n",
            "batch_normalization_6/gamma:0 -- Total:96, Zeros: 0.0000%\n",
            "batch_normalization_6/beta:0 -- Total:96, Zeros: 0.0000%\n",
            "batch_normalization_6/moving_mean:0 -- Total:96, Zeros: 0.0000%\n",
            "batch_normalization_6/moving_variance:0 -- Total:96, Zeros: 0.0000%\n",
            "separable_conv2d_9/depthwise_kernel:0 -- Total:864, Zeros: 0.0000%\n",
            "separable_conv2d_9/pointwise_kernel:0 -- Total:9216, Zeros: 19.9436%\n",
            "separable_conv2d_9/bias:0 -- Total:96, Zeros: 0.0000%\n",
            "fc1/kernel:0 -- Total:96, Zeros: 19.7917%\n",
            "fc1/bias:0 -- Total:1, Zeros: 0.0000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKIRfZDn02rV",
        "colab_type": "code",
        "outputId": "381b3b16-323b-4946-bc78-8abed81c2410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Saving pruned model to: ', \"Avocado_hyper3DNet_pruned.h5\")\n",
        "tf.keras.models.save_model(final_model, \"Avocado_hyper3DNet_pruned.h5\", \n",
        "                        include_optimizer=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving pruned model to:  Avocado_hyper3DNet_pruned.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5tkgm44OZDt",
        "colab_type": "text"
      },
      "source": [
        "# Predict and Calculate Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVT1KBWvEODg",
        "colab_type": "code",
        "outputId": "cb02bab7-a175-4c96-fd7c-54bb65f53c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from operator import truediv\n",
        "import h5py\n",
        "import pickle\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, cohen_kappa_score, confusion_matrix\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "\n",
        "tf.keras.backend.set_image_data_format('channels_last')\n",
        "tf.keras.backend.set_learning_phase(0)\n",
        "\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Prepare lists to save metrics\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "windowSize = train_x.shape[1]\n",
        "classes = 2\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
        "cvoa = []\n",
        "cvaa = []\n",
        "cvka = []\n",
        "cvpre = []\n",
        "cvrec = []\n",
        "cvf1 = []\n",
        "\n",
        "\n",
        "def AA_andEachClassAccuracy(confusion_m):\n",
        "    list_diag = np.diag(confusion_m)\n",
        "    list_raw_sum = np.sum(confusion_m, axis=1)\n",
        "    each_ac = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
        "    average_acc = np.mean(each_ac)\n",
        "    return each_ac, average_acc\n",
        "\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "PREDICT AND CALCULATE METRICS\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "loaded_model = tf.keras.models.load_model(\"weights-hyper3dnet\" + 'AVOCADO' + str(1) + \"-best_3layers_4filters.h5\")\n",
        "epochs = 8\n",
        "batch_size = 32;\n",
        "num_train_samples = train_x.shape[0]\n",
        "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
        "print(end_step)\n",
        "\n",
        "dataset = 'AVOCADO'\n",
        "# Initialize\n",
        "confmatrices = np.zeros((10, int(classes), int(classes)))\n",
        "\n",
        "ntrain = 1\n",
        "for train, test in kfold.split(train_x, train_y):\n",
        "    ytest = train_y[test]\n",
        "\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    PRUNING\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    new_pruning_params = {\n",
        "          'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.10,\n",
        "                                                      final_sparsity=0.30,\n",
        "                                                      begin_step=0,\n",
        "                                                      end_step=end_step,\n",
        "                                                      frequency=100)\n",
        "    }\n",
        "\n",
        "    new_pruned_model = sparsity.prune_low_magnitude(loaded_model, **new_pruning_params)\n",
        "\n",
        "    new_pruned_model.load_weights(\"pruned-weights-hyper3dnet\" + dataset + str(ntrain) + \"-best_3layers_4filters.h5\")\n",
        "    ypred = new_pruned_model.predict(train_x[test])\n",
        "    ypred = ypred.round()\n",
        "\n",
        "    sess = tf.Session()\n",
        "    with sess.as_default():\n",
        "        con_mat = tf.math.confusion_matrix(labels=ytest,\n",
        "                                           predictions=ypred).numpy()\n",
        "\n",
        "    con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=3)\n",
        "    classes_list = list(range(0, int(classes)))\n",
        "    con_mat_df = pd.DataFrame(con_mat_norm, index=classes_list, columns=classes_list)\n",
        "\n",
        "    confmatrices[ntrain - 1, :, :] = con_mat_df.values\n",
        "\n",
        "    # Calculate metrics\n",
        "    oa = accuracy_score(ytest, ypred)\n",
        "    confusion = confusion_matrix(ytest, ypred)\n",
        "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
        "    kappa = cohen_kappa_score(ytest, ypred)\n",
        "    prec, rec, f1, support = precision_recall_fscore_support(ytest, ypred, average='macro')\n",
        "\n",
        "    # Add metrics to the list\n",
        "    cvoa.append(oa * 100)\n",
        "    cvaa.append(aa * 100)\n",
        "    cvka.append(kappa * 100)\n",
        "    cvpre.append(prec * 100)\n",
        "    cvrec.append(rec * 100)\n",
        "    cvf1.append(f1 * 100)\n",
        "\n",
        "    ntrain += 1\n",
        "\n",
        "file_name = \"classification_report_hyper3dnet_pruned_\" + dataset + \".txt\"\n",
        "with open(file_name, 'w') as x_file:\n",
        "    x_file.write(\"Overall accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvoa)), float(np.std(cvoa))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"Average accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvaa)), float(np.std(cvaa))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"Kappa accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvka)), float(np.std(cvka))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"Precision accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvpre)), float(np.std(cvpre))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"Recall accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvrec)), float(np.std(cvrec))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"F1 accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvf1)), float(np.std(cvf1))))\n",
        "\n",
        "# Calculate mean and std\n",
        "means = np.mean(confmatrices * 100, axis=0)\n",
        "stds = np.std(confmatrices * 100, axis=0)\n",
        "\n",
        "def plot_confusion_matrix(cm, cms, classescf,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classescf))\n",
        "    plt.xticks(tick_marks, classescf, rotation=45)\n",
        "    plt.yticks(tick_marks, classescf)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "\n",
        "            if (cm[i, j] == 100 or cm[i, j] == 0) and cms[i, j] == 0:\n",
        "                plt.text(j, i, '{0:.0f}'.format(cm[i, j]) + '\\n$\\pm$' + '{0:.0f}'.format(cms[i, j]),\n",
        "                         horizontalalignment=\"center\",\n",
        "                         verticalalignment=\"center\", fontsize=15,\n",
        "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "            else:\n",
        "                plt.text(j, i, '{0:.2f}'.format(cm[i, j]) + '\\n$\\pm$' + '{0:.2f}'.format(cms[i, j]),\n",
        "                         horizontalalignment=\"center\",\n",
        "                         verticalalignment=\"center\", fontsize=15,\n",
        "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "with open('meanshyper3dnetp', 'wb') as f:\n",
        "    pickle.dump(means, f)\n",
        "with open('stdshyper3dnetp', 'wb') as f:\n",
        "    pickle.dump(stds, f)\n",
        "with open('cvf1hyper3dnetp', 'wb') as f:\n",
        "    pickle.dump(cvf1, f)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "classes_list = list(range(0, int(classes)))\n",
        "plt.figure()\n",
        "plot_confusion_matrix(means, stds, classescf=classes_list)\n",
        "\n",
        "plt.savefig('MatrixConfusion_AVOCADO_hyper3dnet_pruned.png', dpi=1200)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAEmCAYAAAAnRIjxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP0l1gscQ8kSCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}