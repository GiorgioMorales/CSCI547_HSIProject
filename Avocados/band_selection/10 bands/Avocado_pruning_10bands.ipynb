{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avocado_pruning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApyQTRzMcUCB",
        "colab_type": "text"
      },
      "source": [
        "# Prepare tensorflow-model-optimization for pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIe8xTeVtIWd",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWNPotwubYRu",
        "colab_type": "code",
        "outputId": "fd3c3683-04a3-4b70-f510-91e88b12568c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip uninstall -y tf-nightly\n",
        "! pip install -U tensorflow-gpu==1.14.0\n",
        "\n",
        "! pip install tensorflow-model-optimization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.0:\n",
            "  Successfully uninstalled tensorflow-1.15.0\n",
            "\u001b[33mWARNING: Skipping tf-nightly as it is not installed.\u001b[0m\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 43kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 31.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.27.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (45.2.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.8.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n",
            "Collecting tensorflow-model-optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/c4/4c3d011e432bd9c19f0323f7da7d3f783402615e4c3b5a98416c7da9cb05/tensorflow_model_optimization-0.2.1-py2.py3-none-any.whl (93kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 4.6MB/s \n",
            "\u001b[?25hCollecting enum34~=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/63/f6/ccb1c83687756aeabbf3ca0f213508fcfb03883ff200d201b3a4c60cedcc/enum34-1.1.10-py3-none-any.whl\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.12.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.17.5)\n",
            "Installing collected packages: enum34, tensorflow-model-optimization\n",
            "Successfully installed enum34-1.1.10 tensorflow-model-optimization-0.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBfBLXz1mCNV",
        "colab_type": "code",
        "outputId": "d0a5169e-2763-4818-9c60-c141f76fffcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "%load_ext tensorboard\n",
        "import tensorboard\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mk1dYHpbicZ",
        "colab_type": "text"
      },
      "source": [
        "#Download dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu64LC4Wm1oc",
        "colab_type": "code",
        "outputId": "b435c916-2e90-4317-e7a1-8ae259f36211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!pip install PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.11)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.7.2)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (45.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWT-iIqSb_46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://drive.google.com/open?id=1Wz2xqSZSjLDzXXTLdkf6zyTUUcBopn3i\n",
        "download = drive.CreateFile({'id': '1Wz2xqSZSjLDzXXTLdkf6zyTUUcBopn3i'})\n",
        "download.GetContentFile('avocado_dataset_w64.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRDlBcilciuY",
        "colab_type": "text"
      },
      "source": [
        "# Read Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRqt2u-MVfZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "from operator import truediv\n",
        "import h5py\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, cohen_kappa_score, confusion_matrix\n",
        "\n",
        "import tensorboard\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Data augmentation functions\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "def add_rotation_flip(x, y):\n",
        "\n",
        "    x = np.reshape(x, (x.shape[0], x.shape[1], x.shape[2], x.shape[3], 1))\n",
        "\n",
        "    # Flip horizontally\n",
        "    x_h = np.flip(x[:, :, :, :, :], 1)\n",
        "    # Flip vertically\n",
        "    x_v = np.flip(x[:, :, :, :, :], 2)\n",
        "    # Flip horizontally and vertically\n",
        "    x_hv = np.flip(x_h[:, :, :, :, :], 2)\n",
        "\n",
        "    # Concatenate\n",
        "    x = np.concatenate((x, x_h, x_v, x_hv))\n",
        "    y = np.concatenate((y, y, y, y))\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "LOAD HDF5 FILE\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "hdf5_file = h5py.File('avocado_dataset_w64.hdf5', \"r\")\n",
        "train_x = np.array(hdf5_file[\"train_img\"][...])\n",
        "train_y = np.array(hdf5_file[\"train_labels\"][...])\n",
        "\n",
        "# Average consecutive bands\n",
        "img2 = np.zeros((train_x.shape[0], int(train_x.shape[1]/2), int(train_x.shape[2]/2), int(train_x.shape[3] / 2)))\n",
        "for n in range(0, train_x.shape[0]):\n",
        "    xt = cv2.resize(np.float32(train_x[n, :, :, :]), (32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "    for i in range(0, train_x.shape[3], 2):\n",
        "        img2[n, :, :, int(i / 2)] = (xt[:, :, i] + xt[:, :, i + 1]) / 2.\n",
        "\n",
        "train_x = img2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3wrK8dNe-T7",
        "colab_type": "code",
        "outputId": "49028072-74c9-4edf-81ab-12d9ef4f1cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "temp = np.zeros((train_x.shape[0], train_x.shape[1], train_x.shape[2], 10))\n",
        "\n",
        "temp[:, :, :, 0] = train_x[:, :, :,24]\n",
        "temp[:, :, :, 1] = train_x[:, :, :,66]\n",
        "temp[:, :, :, 2] = train_x[:, :, :,73]\n",
        "temp[:, :, :, 3] = train_x[:, :, :,131]\n",
        "temp[:, :, :, 4] = train_x[:, :, :,138]\n",
        "temp[:, :, :, 5] = train_x[:, :, :,140]\n",
        "temp[:, :, :, 6] = train_x[:, :, :,143]\n",
        "temp[:, :, :, 7] = train_x[:, :, :,145]\n",
        "temp[:, :, :, 8] = train_x[:, :, :,147]\n",
        "temp[:, :, :, 9] = train_x[:, :, :,149]\n",
        "\n",
        "\n",
        "train_x = temp\n",
        "\n",
        "train_x, train_y = add_rotation_flip(train_x, train_y)\n",
        "print(train_x.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(964, 32, 32, 10, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvx55MBgcrZJ",
        "colab_type": "text"
      },
      "source": [
        "# Trained pruned network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f2xU6uWWAuz",
        "colab_type": "code",
        "outputId": "7b5cf512-55e2-42a9-a1b0-64dbb832a019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "data = 'AVOCADO'\n",
        "loaded_model = tf.keras.models.load_model(\"weights10-hyper3dnet\" + data + str(1) + \"-best_3layers_4filters.h5\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psE2WVq7DItg",
        "colab_type": "code",
        "outputId": "1a921a2b-3e97-43b0-b443-93495a577811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "source": [
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "epochs = 8\n",
        "batch_size = 16;\n",
        "num_train_samples = train_x.shape[0]\n",
        "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
        "print(end_step)\n",
        "\n",
        "new_pruning_params = {\n",
        "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.5,\n",
        "                                                   final_sparsity=0.9,\n",
        "                                                   begin_step=0,\n",
        "                                                   end_step=end_step,\n",
        "                                                   frequency=100)\n",
        "}\n",
        "\n",
        "new_pruned_model = sparsity.prune_low_magnitude(loaded_model, **new_pruning_params)\n",
        "new_pruned_model.summary()\n",
        "\n",
        "new_pruned_model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer='adadelta',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "488\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.debugging.assert_greater_equal is deprecated. Please use tf.compat.v1.debugging.assert_greater_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_schedule.py:240: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py:59: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 32, 32, 10, 1)]   0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv3d_3 (None, 32, 32, 10, 16)    882       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_reshape_ (None, 32, 32, 160)       1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dropout_ (None, 32, 32, 160)       1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_separabl (None, 32, 32, 320)       106722    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_batch_no (None, 32, 32, 320)       1281      \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_activati (None, 32, 32, 320)       1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_separabl (None, 16, 16, 256)       166978    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_batch_no (None, 16, 16, 256)       1025      \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_activati (None, 16, 16, 256)       1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_separabl (None, 8, 8, 256)         133634    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_activati (None, 8, 8, 256)         1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_global_a (None, 256)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_fc1 (Pru (None, 1)                 515       \n",
            "=================================================================\n",
            "Total params: 411,043\n",
            "Trainable params: 210,529\n",
            "Non-trainable params: 200,514\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjYBXiSTtaDt",
        "colab_type": "code",
        "outputId": "f98670a5-091c-4e7c-efde-76a8760cd443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "windowSize = train_x.shape[1]\n",
        "classes = 2\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
        "cvoa = []\n",
        "cvaa = []\n",
        "cvka = []\n",
        "cvpre = []\n",
        "cvrec = []\n",
        "cvf1 = []\n",
        "cva1 = []\n",
        "cva2 = []\n",
        "cva3 = []\n",
        "\n",
        "\n",
        "data = 'AVOCADO'\n",
        "ntrain = 1\n",
        "for train, test in kfold.split(train_x, train_y):\n",
        "\n",
        "    ytrain = train_y[train]\n",
        "    ytest = train_y[test]\n",
        "\n",
        "    xtrain = train_x[train]\n",
        "    xtest = train_x[test]\n",
        "\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    PRUNING\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    new_pruning_params = {\n",
        "          'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.20,\n",
        "                                                      final_sparsity=0.25,\n",
        "                                                      begin_step=0,\n",
        "                                                      end_step=end_step,\n",
        "                                                      frequency=100)\n",
        "    }\n",
        "\n",
        "    loaded_model.load_weights(\"weights10-hyper3dnet\" + data + str(ntrain) + \"-best_3layers_4filters.h5\")\n",
        "\n",
        "    new_pruned_model = sparsity.prune_low_magnitude(loaded_model, **new_pruning_params)\n",
        "\n",
        "    new_pruned_model.compile(\n",
        "        loss=tf.keras.losses.binary_crossentropy,\n",
        "        optimizer='adadelta',\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    # checkpoint\n",
        "    filepath = \"pruned10-weights-hyper3dnet\" + data + str(ntrain) + \"-best_3layers_4filters.h5\"\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "    callbacks_list = [checkpoint, sparsity.UpdatePruningStep()]\n",
        "\n",
        "    # Train model on dataset\n",
        "    print(data + \": Training\" + str(ntrain) + \"begins...\")\n",
        "    history = new_pruned_model.fit(x=xtrain, y=ytrain, validation_data=(xtest, ytest),\n",
        "                        batch_size=16, epochs=epochs, callbacks=callbacks_list)\n",
        "    \n",
        "    new_pruned_model.save_weights(\"pruned10-weights-hyper3dnet\" + data + str(ntrain) + \"-best_3layers_4filters.h5\")\n",
        "    # new_pruned_model.compile(\n",
        "    #     loss=tf.keras.losses.binary_crossentropy,\n",
        "    #     optimizer='adadelta',\n",
        "    #     metrics=['accuracy'])\n",
        "    ypred = new_pruned_model.predict(xtest)\n",
        "    ypred = ypred.round()\n",
        "    print(np.sum(ypred.transpose()==ytest)/len(ytest))\n",
        "    \n",
        "    ntrain += 1\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AVOCADO: Training1begins...\n",
            "Train on 867 samples, validate on 97 samples\n",
            "Epoch 1/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 4.3008e-05 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned10-weights-hyper3dnetAVOCADO1-best_3layers_4filters.h5\n",
            "867/867 [==============================] - 5s 6ms/sample - loss: 8.9899e-05 - acc: 1.0000 - val_loss: 6.5515e-04 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 3.4750e-05 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 3.9750e-05 - acc: 1.0000 - val_loss: 7.2616e-05 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 1.9070e-05 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 1.8701e-05 - acc: 1.0000 - val_loss: 6.0873e-05 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 6.0943e-05 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 5.9909e-05 - acc: 1.0000 - val_loss: 5.9223e-04 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 2.9099e-05 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 2ms/sample - loss: 2.9183e-04 - acc: 1.0000 - val_loss: 1.4270e-04 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 5.3605e-05 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 5.2454e-05 - acc: 1.0000 - val_loss: 1.5667e-04 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 4.7755e-05 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 5.3271e-05 - acc: 1.0000 - val_loss: 9.3555e-05 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.1387e-04 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 1.1373e-04 - acc: 1.0000 - val_loss: 7.9264e-05 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training2begins...\n",
            "Train on 867 samples, validate on 97 samples\n",
            "Epoch 1/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 2.6465e-04 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned10-weights-hyper3dnetAVOCADO2-best_3layers_4filters.h5\n",
            "867/867 [==============================] - 5s 6ms/sample - loss: 2.8782e-04 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.3709e-04 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 1.3662e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9897\n",
            "Epoch 3/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 2.7272e-04 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 2.6683e-04 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 7.6032e-05 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 7.4980e-05 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 9.4004e-05 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 9.3210e-05 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 1.0980e-04 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 3.4092e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9897\n",
            "Epoch 7/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 2.8762e-04 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 2.8159e-04 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 1.2550e-04 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 1.2507e-04 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training3begins...\n",
            "Train on 867 samples, validate on 97 samples\n",
            "Epoch 1/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 9.8164e-05 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned10-weights-hyper3dnetAVOCADO3-best_3layers_4filters.h5\n",
            "867/867 [==============================] - 5s 6ms/sample - loss: 0.0010 - acc: 0.9988 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 1.4512e-04 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 1.4196e-04 - acc: 1.0000 - val_loss: 0.1661 - val_acc: 0.9588\n",
            "Epoch 3/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 8.0255e-05 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 7.8750e-05 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9897\n",
            "Epoch 4/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 8.6763e-05 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 8.4887e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 6.1272e-04 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 2ms/sample - loss: 5.9987e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 1.6186e-04 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 1.5832e-04 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9988\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 4.4886e-05 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 5.2501e-05 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training4begins...\n",
            "Train on 867 samples, validate on 97 samples\n",
            "Epoch 1/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 1.2256e-05 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned10-weights-hyper3dnetAVOCADO4-best_3layers_4filters.h5\n",
            "867/867 [==============================] - 5s 6ms/sample - loss: 1.2023e-05 - acc: 1.0000 - val_loss: 4.4154e-04 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 5.6760e-05 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 5.9628e-05 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 1.4085e-05 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 1.8031e-05 - acc: 1.0000 - val_loss: 2.6445e-04 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 7.1129e-05 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 7.0883e-05 - acc: 1.0000 - val_loss: 9.2835e-04 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 1.8311e-05 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 8.5196e-05 - acc: 1.0000 - val_loss: 8.3666e-04 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/867 [============================>.] - ETA: 0s - loss: 9.9176e-05 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 9.8834e-05 - acc: 1.0000 - val_loss: 2.7551e-04 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 4.2512e-05 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 4.1628e-05 - acc: 1.0000 - val_loss: 3.7165e-04 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "848/867 [============================>.] - ETA: 0s - loss: 7.6031e-06 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "867/867 [==============================] - 2s 3ms/sample - loss: 8.5947e-06 - acc: 1.0000 - val_loss: 3.1062e-04 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training5begins...\n",
            "Train on 868 samples, validate on 96 samples\n",
            "Epoch 1/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 1.9455e-06 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned10-weights-hyper3dnetAVOCADO5-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 5s 5ms/sample - loss: 1.9018e-06 - acc: 1.0000 - val_loss: 2.0129e-04 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 2.1357e-06 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 2.1283e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 3.8956e-05 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 3.8073e-05 - acc: 1.0000 - val_loss: 2.0667e-04 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 2.9422e-05 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 2.9318e-05 - acc: 1.0000 - val_loss: 5.2390e-05 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 3.5695e-06 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 3.5073e-06 - acc: 1.0000 - val_loss: 3.3783e-05 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 1.7007e-05 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 1.6929e-05 - acc: 1.0000 - val_loss: 8.8132e-04 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 6.4178e-06 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 6.2699e-06 - acc: 1.0000 - val_loss: 1.1125e-04 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 5.6629e-06 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 5.6368e-06 - acc: 1.0000 - val_loss: 5.5305e-05 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training6begins...\n",
            "Train on 868 samples, validate on 96 samples\n",
            "Epoch 1/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 1.7432e-05 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned10-weights-hyper3dnetAVOCADO6-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 1.9740e-05 - acc: 1.0000 - val_loss: 5.8624e-05 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 3.4243e-06 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 3.1679e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 1.6329e-04 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 1.5991e-04 - acc: 1.0000 - val_loss: 6.5435e-04 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 1.0656e-04 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 1.2372e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 1.8173e-05 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 2ms/sample - loss: 1.7769e-05 - acc: 1.0000 - val_loss: 7.2276e-04 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 4.8065e-06 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 4.9422e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 5.0355e-05 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 4.9240e-05 - acc: 1.0000 - val_loss: 5.1026e-04 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 1.9014e-05 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 0.0012 - acc: 0.9988 - val_loss: 2.4582e-04 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training7begins...\n",
            "Train on 868 samples, validate on 96 samples\n",
            "Epoch 1/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 2.7844e-06 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned10-weights-hyper3dnetAVOCADO7-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 5s 5ms/sample - loss: 3.4362e-06 - acc: 1.0000 - val_loss: 8.3554e-05 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 3.9515e-06 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 3.8772e-06 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 7.0561e-06 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 6.9408e-06 - acc: 1.0000 - val_loss: 1.1057e-04 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 5.1835e-06 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 5.1273e-06 - acc: 1.0000 - val_loss: 5.9850e-06 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 1.0101e-05 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 1.0379e-05 - acc: 1.0000 - val_loss: 5.3331e-06 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 6.7690e-06 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 6.6613e-06 - acc: 1.0000 - val_loss: 6.9663e-06 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 2.4967e-05 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 2.4479e-05 - acc: 1.0000 - val_loss: 8.0968e-06 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 1.1095e-05 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 1.2885e-05 - acc: 1.0000 - val_loss: 1.0213e-05 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training8begins...\n",
            "Train on 868 samples, validate on 96 samples\n",
            "Epoch 1/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 6.4555e-06 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 0.97917, saving model to pruned10-weights-hyper3dnetAVOCADO8-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 5s 5ms/sample - loss: 6.4308e-06 - acc: 1.0000 - val_loss: 0.0357 - val_acc: 0.9792\n",
            "Epoch 2/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 5.6409e-05 - acc: 1.0000\n",
            "Epoch 00002: val_acc improved from 0.97917 to 1.00000, saving model to pruned10-weights-hyper3dnetAVOCADO8-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 5.5163e-05 - acc: 1.0000 - val_loss: 4.0212e-04 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 2.3985e-05 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 2.5349e-05 - acc: 1.0000 - val_loss: 3.9167e-04 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 3.2730e-05 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 3.2580e-05 - acc: 1.0000 - val_loss: 5.5380e-04 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 1.3760e-05 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 1.3453e-05 - acc: 1.0000 - val_loss: 6.6061e-04 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 4.9118e-05 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 4.8897e-05 - acc: 1.0000 - val_loss: 3.6320e-04 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 7.9431e-06 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 3.2053e-05 - acc: 1.0000 - val_loss: 6.1434e-04 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 2.8234e-05 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 2.8534e-05 - acc: 1.0000 - val_loss: 2.7775e-04 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training9begins...\n",
            "Train on 868 samples, validate on 96 samples\n",
            "Epoch 1/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 5.2277e-06 - acc: 1.0000\n",
            "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to pruned10-weights-hyper3dnetAVOCADO9-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 4s 5ms/sample - loss: 5.2176e-06 - acc: 1.0000 - val_loss: 2.0647e-04 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 7.2779e-06 - acc: 1.0000\n",
            "Epoch 00002: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 8.3358e-06 - acc: 1.0000 - val_loss: 2.4894e-04 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 8.9736e-06 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 8.7680e-06 - acc: 1.0000 - val_loss: 2.6071e-04 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 6.7880e-06 - acc: 1.0000\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 6.6740e-06 - acc: 1.0000 - val_loss: 2.9460e-04 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9988\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 0.0014 - acc: 0.9988 - val_loss: 2.6622e-04 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 3.5040e-06 - acc: 1.0000\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 1.6735e-05 - acc: 1.0000 - val_loss: 2.4821e-04 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 1.1458e-05 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 3.7162e-04 - acc: 1.0000 - val_loss: 2.1692e-04 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 1.1813e-05 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 1.1799e-05 - acc: 1.0000 - val_loss: 2.2746e-04 - val_acc: 1.0000\n",
            "1.0\n",
            "AVOCADO: Training10begins...\n",
            "Train on 868 samples, validate on 96 samples\n",
            "Epoch 1/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9965\n",
            "Epoch 00001: val_acc improved from -inf to 0.98958, saving model to pruned10-weights-hyper3dnetAVOCADO10-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 5s 5ms/sample - loss: 0.0173 - acc: 0.9954 - val_loss: 0.0282 - val_acc: 0.9896\n",
            "Epoch 2/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9988\n",
            "Epoch 00002: val_acc improved from 0.98958 to 1.00000, saving model to pruned10-weights-hyper3dnetAVOCADO10-best_3layers_4filters.h5\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0051 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 2.6996e-04 - acc: 1.0000\n",
            "Epoch 00003: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 2.6385e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9965\n",
            "Epoch 00004: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 0.0127 - acc: 0.9965 - val_loss: 0.0156 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 3.2812e-04 - acc: 1.0000\n",
            "Epoch 00005: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 3.3035e-04 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "848/868 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9988\n",
            "Epoch 00006: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 0.0016 - acc: 0.9988 - val_loss: 0.0026 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 7.0353e-04 - acc: 1.0000\n",
            "Epoch 00007: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 7.0029e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "864/868 [============================>.] - ETA: 0s - loss: 2.0003e-04 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 1.00000\n",
            "868/868 [==============================] - 2s 3ms/sample - loss: 1.9911e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSmz9PSRTvPP",
        "colab_type": "code",
        "outputId": "d52d5160-b1f8-4f4c-ad87-c46c7f07d886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "new_pruned_model.load_weights(\"pruned10-weights-hyper3dnet\" + data + str(2) + \"-best_3layers_4filters.h5\")\n",
        "final_model = sparsity.strip_pruning(new_pruned_model)\n",
        "final_model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 32, 32, 10, 1)]   0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 32, 32, 10, 16)    448       \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 32, 32, 160)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32, 32, 160)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_7 (Separabl (None, 32, 32, 320)       55520     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 32, 320)       1280      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 320)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_8 (Separabl (None, 16, 16, 256)       85056     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_9 (Separabl (None, 8, 8, 256)         68096     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 211,681\n",
            "Trainable params: 210,529\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8drkv1mK1CUb",
        "colab_type": "code",
        "outputId": "3cd2d305-4d9b-47ee-ea65-35405909154d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "import numpy as np\n",
        "for i, w in enumerate(final_model.get_weights()):\n",
        "    print(\n",
        "        \"{} -- Total:{}, Zeros: {:.4f}%\".format(\n",
        "            final_model.weights[i].name, w.size, np.sum(w == 0) / w.size * 100\n",
        "        )\n",
        "    )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv3d_3/kernel:0 -- Total:432, Zeros: 25.0000%\n",
            "conv3d_3/bias:0 -- Total:16, Zeros: 0.0000%\n",
            "separable_conv2d_7/depthwise_kernel:0 -- Total:4000, Zeros: 0.0000%\n",
            "separable_conv2d_7/pointwise_kernel:0 -- Total:51200, Zeros: 24.9707%\n",
            "separable_conv2d_7/bias:0 -- Total:320, Zeros: 0.0000%\n",
            "batch_normalization_5/gamma:0 -- Total:320, Zeros: 0.0000%\n",
            "batch_normalization_5/beta:0 -- Total:320, Zeros: 0.0000%\n",
            "batch_normalization_5/moving_mean:0 -- Total:320, Zeros: 0.0000%\n",
            "batch_normalization_5/moving_variance:0 -- Total:320, Zeros: 0.0000%\n",
            "separable_conv2d_8/depthwise_kernel:0 -- Total:2880, Zeros: 0.0000%\n",
            "separable_conv2d_8/pointwise_kernel:0 -- Total:81920, Zeros: 24.9707%\n",
            "separable_conv2d_8/bias:0 -- Total:256, Zeros: 0.0000%\n",
            "batch_normalization_6/gamma:0 -- Total:256, Zeros: 0.0000%\n",
            "batch_normalization_6/beta:0 -- Total:256, Zeros: 0.0000%\n",
            "batch_normalization_6/moving_mean:0 -- Total:256, Zeros: 0.0000%\n",
            "batch_normalization_6/moving_variance:0 -- Total:256, Zeros: 0.0000%\n",
            "separable_conv2d_9/depthwise_kernel:0 -- Total:2304, Zeros: 0.0000%\n",
            "separable_conv2d_9/pointwise_kernel:0 -- Total:65536, Zeros: 24.9710%\n",
            "separable_conv2d_9/bias:0 -- Total:256, Zeros: 0.0000%\n",
            "fc1/kernel:0 -- Total:256, Zeros: 25.0000%\n",
            "fc1/bias:0 -- Total:1, Zeros: 0.0000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKIRfZDn02rV",
        "colab_type": "code",
        "outputId": "9b220b54-7db3-46f5-8ee1-d086af101b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Saving pruned model to: ', \"Avocado_hyper3DNet_pruned.h5\")\n",
        "tf.keras.models.save_model(final_model, \"Avocado_hyper3DNet_pruned_10bands.h5\", \n",
        "                        include_optimizer=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving pruned model to:  Avocado_hyper3DNet_pruned.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5tkgm44OZDt",
        "colab_type": "text"
      },
      "source": [
        "# Predict and Calculate Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVT1KBWvEODg",
        "colab_type": "code",
        "outputId": "c8da8d56-26af-48fc-8a77-ed9cd749b51a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from operator import truediv\n",
        "import h5py\n",
        "import pickle\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, cohen_kappa_score, confusion_matrix\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "\n",
        "tf.keras.backend.set_image_data_format('channels_last')\n",
        "tf.keras.backend.set_learning_phase(0)\n",
        "\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Prepare lists to save metrics\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "windowSize = train_x.shape[1]\n",
        "classes = 2\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
        "cvoa = []\n",
        "cvaa = []\n",
        "cvka = []\n",
        "cvpre = []\n",
        "cvrec = []\n",
        "cvf1 = []\n",
        "\n",
        "\n",
        "def AA_andEachClassAccuracy(confusion_m):\n",
        "    list_diag = np.diag(confusion_m)\n",
        "    list_raw_sum = np.sum(confusion_m, axis=1)\n",
        "    each_ac = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
        "    average_acc = np.mean(each_ac)\n",
        "    return each_ac, average_acc\n",
        "\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "PREDICT AND CALCULATE METRICS\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "loaded_model = tf.keras.models.load_model(\"weights10-hyper3dnet\" + 'AVOCADO' + str(1) + \"-best_3layers_4filters.h5\")\n",
        "epochs = 8\n",
        "batch_size = 32;\n",
        "num_train_samples = train_x.shape[0]\n",
        "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
        "print(end_step)\n",
        "\n",
        "dataset = 'AVOCADO'\n",
        "# Initialize\n",
        "confmatrices = np.zeros((10, int(classes), int(classes)))\n",
        "\n",
        "ntrain = 1\n",
        "for train, test in kfold.split(train_x, train_y):\n",
        "    ytest = train_y[test]\n",
        "\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    PRUNING\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    new_pruning_params = {\n",
        "          'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.10,\n",
        "                                                      final_sparsity=0.30,\n",
        "                                                      begin_step=0,\n",
        "                                                      end_step=end_step,\n",
        "                                                      frequency=100)\n",
        "    }\n",
        "\n",
        "    new_pruned_model = sparsity.prune_low_magnitude(loaded_model, **new_pruning_params)\n",
        "\n",
        "    new_pruned_model.load_weights(\"pruned10-weights-hyper3dnet\" + dataset + str(ntrain) + \"-best_3layers_4filters.h5\")\n",
        "    ypred = new_pruned_model.predict(train_x[test])\n",
        "    ypred = ypred.round()\n",
        "\n",
        "    sess = tf.Session()\n",
        "    with sess.as_default():\n",
        "        con_mat = tf.math.confusion_matrix(labels=ytest,\n",
        "                                           predictions=ypred).numpy()\n",
        "\n",
        "    con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=3)\n",
        "    classes_list = list(range(0, int(classes)))\n",
        "    con_mat_df = pd.DataFrame(con_mat_norm, index=classes_list, columns=classes_list)\n",
        "\n",
        "    confmatrices[ntrain - 1, :, :] = con_mat_df.values\n",
        "\n",
        "    # Calculate metrics\n",
        "    oa = accuracy_score(ytest, ypred)\n",
        "    confusion = confusion_matrix(ytest, ypred)\n",
        "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
        "    kappa = cohen_kappa_score(ytest, ypred)\n",
        "    prec, rec, f1, support = precision_recall_fscore_support(ytest, ypred, average='macro')\n",
        "\n",
        "    # Add metrics to the list\n",
        "    cvoa.append(oa * 100)\n",
        "    cvaa.append(aa * 100)\n",
        "    cvka.append(kappa * 100)\n",
        "    cvpre.append(prec * 100)\n",
        "    cvrec.append(rec * 100)\n",
        "    cvf1.append(f1 * 100)\n",
        "\n",
        "    ntrain += 1\n",
        "\n",
        "file_name = \"classification_report_hyper3dnet_pruned_10bands_\" + dataset + \".txt\"\n",
        "with open(file_name, 'w') as x_file:\n",
        "    x_file.write(\"Overall accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvoa)), float(np.std(cvoa))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"Average accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvaa)), float(np.std(cvaa))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"Kappa accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvka)), float(np.std(cvka))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"Precision accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvpre)), float(np.std(cvpre))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"Recall accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvrec)), float(np.std(cvrec))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"F1 accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvf1)), float(np.std(cvf1))))\n",
        "\n",
        "# Calculate mean and std\n",
        "means = np.mean(confmatrices * 100, axis=0)\n",
        "stds = np.std(confmatrices * 100, axis=0)\n",
        "\n",
        "def plot_confusion_matrix(cm, cms, classescf,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classescf))\n",
        "    plt.xticks(tick_marks, classescf, rotation=45)\n",
        "    plt.yticks(tick_marks, classescf)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "\n",
        "            if (cm[i, j] == 100 or cm[i, j] == 0) and cms[i, j] == 0:\n",
        "                plt.text(j, i, '{0:.0f}'.format(cm[i, j]) + '\\n$\\pm$' + '{0:.0f}'.format(cms[i, j]),\n",
        "                         horizontalalignment=\"center\",\n",
        "                         verticalalignment=\"center\", fontsize=15,\n",
        "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "            else:\n",
        "                plt.text(j, i, '{0:.2f}'.format(cm[i, j]) + '\\n$\\pm$' + '{0:.2f}'.format(cms[i, j]),\n",
        "                         horizontalalignment=\"center\",\n",
        "                         verticalalignment=\"center\", fontsize=15,\n",
        "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "with open('meanshyper3dnet10p', 'wb') as f:\n",
        "    pickle.dump(means, f)\n",
        "with open('stdshyper3dnet10p', 'wb') as f:\n",
        "    pickle.dump(stds, f)\n",
        "with open('cvf1hyper3dnet10p', 'wb') as f:\n",
        "    pickle.dump(cvf1, f)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "classes_list = list(range(0, int(classes)))\n",
        "plt.figure()\n",
        "plot_confusion_matrix(means, stds, classescf=classes_list)\n",
        "\n",
        "plt.savefig('MatrixConfusion_AVOCADO_hyper3dnet_pruned_10bands.png', dpi=1200)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAEmCAYAAAAnRIjxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nioiERAlWRCQk/x8UmQOpu7+nkgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}