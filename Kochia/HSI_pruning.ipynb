{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HSI_pruning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApyQTRzMcUCB",
        "colab_type": "text"
      },
      "source": [
        "# Prepare tensorflow-model-optimization for pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWNPotwubYRu",
        "colab_type": "code",
        "outputId": "c80db848-c01a-4918-a060-c142ed2ff513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip uninstall -y tf-nightly\n",
        "! pip install -U tensorflow-gpu==1.14.0\n",
        "\n",
        "! pip install tensorflow-model-optimization"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.0:\n",
            "  Successfully uninstalled tensorflow-1.15.0\n",
            "\u001b[33mWARNING: Skipping tf-nightly as it is not installed.\u001b[0m\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 55.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 46.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.27.1)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (45.1.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/c4/4c3d011e432bd9c19f0323f7da7d3f783402615e4c3b5a98416c7da9cb05/tensorflow_model_optimization-0.2.1-py2.py3-none-any.whl (93kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 33.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 92kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 3.0MB/s \n",
            "\u001b[?25hCollecting enum34~=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.17.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.12.0)\n",
            "Installing collected packages: enum34, tensorflow-model-optimization\n",
            "Successfully installed enum34-1.1.6 tensorflow-model-optimization-0.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBfBLXz1mCNV",
        "colab_type": "code",
        "outputId": "81127361-a6f1-4c66-89ea-a0cdf554efca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "%load_ext tensorboard\n",
        "import tensorboard\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mk1dYHpbicZ",
        "colab_type": "text"
      },
      "source": [
        "#Download dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu64LC4Wm1oc",
        "colab_type": "code",
        "outputId": "a1c178fa-b2aa-4989-e03c-be95272b95dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.11)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.7.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (45.1.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWT-iIqSb_46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://drive.google.com/open?id=1swPiOWtQ80zWHOK0pyWDuhilhRDkFux8/view?usp=sharing\n",
        "#https://drive.google.com/open?id=1swPiOWtQ80zWHOK0pyWDuhilhRDkFux8\n",
        "download = drive.CreateFile({'id': '1swPiOWtQ80zWHOK0pyWDuhilhRDkFux8'})\n",
        "download.GetContentFile('weed_dataset_w25.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRDlBcilciuY",
        "colab_type": "text"
      },
      "source": [
        "# Read Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRqt2u-MVfZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "from operator import truediv\n",
        "import h5py\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, cohen_kappa_score, confusion_matrix\n",
        "\n",
        "import tensorboard\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syCzlwNcr-di",
        "colab_type": "code",
        "outputId": "9fbd530d-7e0b-492c-e27b-1ac691478052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "LOAD HDF5 FILE\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "hdf5_file = h5py.File('weed_dataset_w25.hdf5', \"r\")\n",
        "train_x = np.array(hdf5_file[\"train_img\"][...])\n",
        "# train_x = train_x / np.max(train_x)\n",
        "# train_x = np.clip(train_x, 0, 1)\n",
        "#train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], train_x.shape[2], train_x.shape[3], 1))\n",
        "train_y = np.array(hdf5_file[\"train_labels\"][...])\n",
        "\n",
        "# Average consecutive bands\n",
        "img2 = np.zeros((train_x.shape[0], train_x.shape[1], train_x.shape[2], int(train_x.shape[3]/2)))\n",
        "for n in range(0, train_x.shape[0]):\n",
        "    # Average consecutive bands\n",
        "    for i in range(0, train_x.shape[3], 2):\n",
        "        img2[n, :, :, int(i/2)] = (train_x[n, :, :, i] + train_x[n, :, :, i + 1]) / 2.\n",
        "\n",
        "train_x = img2\n",
        "\n",
        "print(train_x.shape)\n",
        "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], train_x.shape[2], train_x.shape[3], 1))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6316, 25, 25, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvx55MBgcrZJ",
        "colab_type": "text"
      },
      "source": [
        "# Trained pruned network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f2xU6uWWAuz",
        "colab_type": "code",
        "outputId": "b9738d3a-18c1-4e6f-e9bf-5fe7f85fcb76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "data = 'WEED'\n",
        "loaded_model = tf.keras.models.load_model(\"weights-hyper3dnet\" + data + str(1) + \"-best_3layers_4filters.h5\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psE2WVq7DItg",
        "colab_type": "code",
        "outputId": "4b048e2a-c7ba-4624-8fa8-a35ace4b0042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "epochs = 8\n",
        "batch_size = 32;\n",
        "num_train_samples = train_x.shape[0]\n",
        "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
        "print(end_step)\n",
        "\n",
        "new_pruning_params = {\n",
        "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                   final_sparsity=0.90,\n",
        "                                                   begin_step=0,\n",
        "                                                   end_step=end_step,\n",
        "                                                   frequency=100)\n",
        "}\n",
        "\n",
        "new_pruned_model = sparsity.prune_low_magnitude(loaded_model, **new_pruning_params)\n",
        "new_pruned_model.summary()\n",
        "\n",
        "new_pruned_model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer='adadelta',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1584\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.debugging.assert_greater_equal is deprecated. Please use tf.compat.v1.debugging.assert_greater_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_schedule.py:240: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py:59: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 25, 25, 150, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv3d_7 (P (None, 25, 25, 150,  1018        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 25, 25, 150,  33          prune_low_magnitude_conv3d_7[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_activation_ (None, 25, 25, 150,  1           prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv3d_8 (P (None, 25, 25, 150,  5770        prune_low_magnitude_activation_15\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 25, 25, 150,  33          prune_low_magnitude_conv3d_8[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_activation_ (None, 25, 25, 150,  1           prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 25, 25, 150,  1           prune_low_magnitude_activation_15\n",
            "                                                                 prune_low_magnitude_activation_16\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_conv3d_9 (P (None, 25, 25, 150,  6922        prune_low_magnitude_concatenate_5\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 25, 25, 150,  33          prune_low_magnitude_conv3d_9[0][0\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_activation_ (None, 25, 25, 150,  1           prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_concatenate (None, 25, 25, 150,  1           prune_low_magnitude_concatenate_5\n",
            "                                                                 prune_low_magnitude_activation_17\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_reshape_3 ( (None, 25, 25, 3600) 1           prune_low_magnitude_concatenate_6\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_separable_c (None, 25, 25, 128)  954130      prune_low_magnitude_reshape_3[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 25, 25, 128)  513         prune_low_magnitude_separable_con\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_activation_ (None, 25, 25, 128)  1           prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_separable_c (None, 13, 13, 128)  34050       prune_low_magnitude_activation_18\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 13, 13, 128)  513         prune_low_magnitude_separable_con\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_activation_ (None, 13, 13, 128)  1           prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_separable_c (None, 7, 7, 128)    34050       prune_low_magnitude_activation_19\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 7, 7, 128)    513         prune_low_magnitude_separable_con\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_activation_ (None, 7, 7, 128)    1           prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_separable_c (None, 4, 4, 128)    34050       prune_low_magnitude_activation_20\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_batch_norma (None, 4, 4, 128)    513         prune_low_magnitude_separable_con\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_activation_ (None, 4, 4, 128)    1           prune_low_magnitude_batch_normali\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_flatten_3 ( (None, 2048)         1           prune_low_magnitude_activation_21\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_3 ( (None, 2048)         1           prune_low_magnitude_flatten_3[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_fc3 (PruneL (None, 3)            12293       prune_low_magnitude_dropout_3[0][\n",
            "==================================================================================================\n",
            "Total params: 1,084,446\n",
            "Trainable params: 560,403\n",
            "Non-trainable params: 524,043\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjYBXiSTtaDt",
        "colab_type": "code",
        "outputId": "aaf99c50-b26c-48dc-f1b0-12b5794bbca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "windowSize = train_x.shape[1]\n",
        "classes = 3\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
        "cvoa = []\n",
        "cvaa = []\n",
        "cvka = []\n",
        "cvpre = []\n",
        "cvrec = []\n",
        "cvf1 = []\n",
        "cva1 = []\n",
        "cva2 = []\n",
        "cva3 = []\n",
        "\n",
        "data = 'WEED'\n",
        "ntrain = 1\n",
        "for train, test in kfold.split(train_x, train_y):\n",
        "\n",
        "    ytrain = tf.keras.utils.to_categorical(train_y[train]).astype(np.int32)\n",
        "    ytest = tf.keras.utils.to_categorical(train_y[test]).astype(np.int32)\n",
        "\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    PRUNING\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    new_pruning_params = {\n",
        "          'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.10,\n",
        "                                                      final_sparsity=0.30,\n",
        "                                                      begin_step=0,\n",
        "                                                      end_step=end_step,\n",
        "                                                      frequency=100)\n",
        "    }\n",
        "\n",
        "    loaded_model.load_weights(\"weights-hyper3dnet\" + data + str(ntrain) + \"-best_3layers_4filters.h5\")\n",
        "\n",
        "    new_pruned_model = sparsity.prune_low_magnitude(loaded_model, **new_pruning_params)\n",
        "    #new_pruned_model.summary()\n",
        "\n",
        "    new_pruned_model.compile(\n",
        "        loss=tf.keras.losses.categorical_crossentropy,\n",
        "        optimizer='adadelta',\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    # checkpoint\n",
        "    filepath = \"pruned-weights-hyper3dnet\" + data + str(ntrain) + \"-best_3layers_4filters.h5\"\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "    callbacks_list = [checkpoint, sparsity.UpdatePruningStep()]\n",
        "\n",
        "    # Train model on dataset\n",
        "    print(data + \": Training\" + str(ntrain) + \"begins...\")\n",
        "    history = new_pruned_model.fit(x=train_x[train], y=ytrain, validation_data=(train_x[test], ytest),\n",
        "                        batch_size=32, epochs=epochs, callbacks=callbacks_list)\n",
        "    \n",
        "    ntrain += 1\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WEED: Training8begins...\n",
            "Train on 5685 samples, validate on 631 samples\n",
            "Epoch 1/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9993\n",
            "Epoch 00001: val_acc improved from -inf to 0.98574, saving model to pruned-weights-hyper3dnetWEED8-best_3layers_4filters.h5\n",
            "5685/5685 [==============================] - 47s 8ms/sample - loss: 0.0038 - acc: 0.9993 - val_loss: 0.0569 - val_acc: 0.9857\n",
            "Epoch 2/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9989\n",
            "Epoch 00002: val_acc did not improve from 0.98574\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0031 - acc: 0.9989 - val_loss: 0.1126 - val_acc: 0.9794\n",
            "Epoch 3/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9986\n",
            "Epoch 00003: val_acc did not improve from 0.98574\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0038 - acc: 0.9986 - val_loss: 0.0830 - val_acc: 0.9810\n",
            "Epoch 4/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9982\n",
            "Epoch 00004: val_acc did not improve from 0.98574\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0044 - acc: 0.9981 - val_loss: 0.1918 - val_acc: 0.9540\n",
            "Epoch 5/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9986\n",
            "Epoch 00005: val_acc did not improve from 0.98574\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0621 - val_acc: 0.9826\n",
            "Epoch 6/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9984\n",
            "Epoch 00006: val_acc improved from 0.98574 to 0.98732, saving model to pruned-weights-hyper3dnetWEED8-best_3layers_4filters.h5\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0032 - acc: 0.9984 - val_loss: 0.0458 - val_acc: 0.9873\n",
            "Epoch 7/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9988\n",
            "Epoch 00007: val_acc did not improve from 0.98732\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0043 - acc: 0.9988 - val_loss: 0.0344 - val_acc: 0.9873\n",
            "Epoch 8/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9986\n",
            "Epoch 00008: val_acc improved from 0.98732 to 0.98891, saving model to pruned-weights-hyper3dnetWEED8-best_3layers_4filters.h5\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0047 - acc: 0.9986 - val_loss: 0.0369 - val_acc: 0.9889\n",
            "WEED: Training9begins...\n",
            "Train on 5685 samples, validate on 631 samples\n",
            "Epoch 1/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9977\n",
            "Epoch 00001: val_acc improved from -inf to 0.98257, saving model to pruned-weights-hyper3dnetWEED9-best_3layers_4filters.h5\n",
            "5685/5685 [==============================] - 41s 7ms/sample - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0535 - val_acc: 0.9826\n",
            "Epoch 2/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9974\n",
            "Epoch 00002: val_acc improved from 0.98257 to 0.98732, saving model to pruned-weights-hyper3dnetWEED9-best_3layers_4filters.h5\n",
            "5685/5685 [==============================] - 35s 6ms/sample - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0489 - val_acc: 0.9873\n",
            "Epoch 3/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9989\n",
            "Epoch 00003: val_acc did not improve from 0.98732\n",
            "5685/5685 [==============================] - 35s 6ms/sample - loss: 0.0041 - acc: 0.9989 - val_loss: 0.0788 - val_acc: 0.9794\n",
            "Epoch 4/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9979\n",
            "Epoch 00004: val_acc did not improve from 0.98732\n",
            "5685/5685 [==============================] - 35s 6ms/sample - loss: 0.0074 - acc: 0.9979 - val_loss: 0.0627 - val_acc: 0.9826\n",
            "Epoch 5/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9970\n",
            "Epoch 00005: val_acc did not improve from 0.98732\n",
            "5685/5685 [==============================] - 35s 6ms/sample - loss: 0.0079 - acc: 0.9970 - val_loss: 0.0456 - val_acc: 0.9873\n",
            "Epoch 6/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9974\n",
            "Epoch 00006: val_acc did not improve from 0.98732\n",
            "5685/5685 [==============================] - 35s 6ms/sample - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0497 - val_acc: 0.9857\n",
            "Epoch 7/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9977\n",
            "Epoch 00007: val_acc improved from 0.98732 to 0.98891, saving model to pruned-weights-hyper3dnetWEED9-best_3layers_4filters.h5\n",
            "5685/5685 [==============================] - 35s 6ms/sample - loss: 0.0090 - acc: 0.9975 - val_loss: 0.0444 - val_acc: 0.9889\n",
            "Epoch 8/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9972\n",
            "Epoch 00008: val_acc did not improve from 0.98891\n",
            "5685/5685 [==============================] - 35s 6ms/sample - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0444 - val_acc: 0.9889\n",
            "WEED: Training10begins...\n",
            "Train on 5685 samples, validate on 631 samples\n",
            "Epoch 1/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9993\n",
            "Epoch 00001: val_acc improved from -inf to 0.99366, saving model to pruned-weights-hyper3dnetWEED10-best_3layers_4filters.h5\n",
            "5685/5685 [==============================] - 41s 7ms/sample - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9937\n",
            "Epoch 2/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9989\n",
            "Epoch 00002: val_acc improved from 0.99366 to 0.99842, saving model to pruned-weights-hyper3dnetWEED10-best_3layers_4filters.h5\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0026 - acc: 0.9989 - val_loss: 0.0039 - val_acc: 0.9984\n",
            "Epoch 3/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9989\n",
            "Epoch 00003: val_acc did not improve from 0.99842\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0029 - acc: 0.9989 - val_loss: 0.0044 - val_acc: 0.9984\n",
            "Epoch 4/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9995\n",
            "Epoch 00004: val_acc did not improve from 0.99842\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0177 - val_acc: 0.9937\n",
            "Epoch 5/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9986\n",
            "Epoch 00005: val_acc did not improve from 0.99842\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0037 - acc: 0.9986 - val_loss: 0.0093 - val_acc: 0.9952\n",
            "Epoch 6/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9982\n",
            "Epoch 00006: val_acc did not improve from 0.99842\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0057 - acc: 0.9982 - val_loss: 0.0186 - val_acc: 0.9889\n",
            "Epoch 7/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9981\n",
            "Epoch 00007: val_acc did not improve from 0.99842\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0078 - val_acc: 0.9952\n",
            "Epoch 8/8\n",
            "5664/5685 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9975\n",
            "Epoch 00008: val_acc did not improve from 0.99842\n",
            "5685/5685 [==============================] - 34s 6ms/sample - loss: 0.0082 - acc: 0.9975 - val_loss: 0.0072 - val_acc: 0.9968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-744aa700c5de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mntrain\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSmz9PSRTvPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1fb7739-33dd-49a7-a7a8-26123dbf2015"
      },
      "source": [
        "new_pruned_model.load_weights(\"pruned-weights-hyper3dnet\" + data + str(2) + \"-best_3layers_4filters.h5\")\n",
        "final_model = sparsity.strip_pruning(new_pruned_model)\n",
        "final_model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 25, 25, 150, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_7 (Conv3D)               (None, 25, 25, 150,  512         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 150,  32          conv3d_7[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 150,  0           batch_normalization_15[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_8 (Conv3D)               (None, 25, 25, 150,  2888        activation_15[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 150,  32          conv3d_8[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 150,  0           batch_normalization_16[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 25, 25, 150,  0           activation_15[1][0]              \n",
            "                                                                 activation_16[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_9 (Conv3D)               (None, 25, 25, 150,  3464        concatenate_5[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 150,  32          conv3d_9[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 150,  0           batch_normalization_17[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 25, 25, 150,  0           concatenate_5[1][0]              \n",
            "                                                                 activation_17[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 25, 25, 3600) 0           concatenate_6[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 25, 25, 128)  493328      reshape_3[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 128)  512         separable_conv2d_9[1][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 128)  0           batch_normalization_18[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 13, 13, 128)  17664       activation_18[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 13, 13, 128)  512         separable_conv2d_10[1][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 13, 13, 128)  0           batch_normalization_19[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 7, 7, 128)    17664       activation_19[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 7, 7, 128)    512         separable_conv2d_11[1][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 7, 7, 128)    0           batch_normalization_20[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 4, 4, 128)    17664       activation_20[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 4, 4, 128)    512         separable_conv2d_12[1][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 4, 4, 128)    0           batch_normalization_21[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 2048)         0           activation_21[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 2048)         0           flatten_3[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc3 (Dense)                     (None, 3)            6147        dropout_3[1][0]                  \n",
            "==================================================================================================\n",
            "Total params: 561,475\n",
            "Trainable params: 560,403\n",
            "Non-trainable params: 1,072\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8drkv1mK1CUb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "9831291d-38b5-426c-a9d2-6756ca864abc"
      },
      "source": [
        "import numpy as np\n",
        "for i, w in enumerate(final_model.get_weights()):\n",
        "    print(\n",
        "        \"{} -- Total:{}, Zeros: {:.4f}%\".format(\n",
        "            final_model.weights[i].name, w.size, np.sum(w == 0) / w.size * 100\n",
        "        )\n",
        "    )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv3d_7/kernel:0 -- Total:504, Zeros: 28.9683%\n",
            "conv3d_7/bias:0 -- Total:8, Zeros: 0.0000%\n",
            "batch_normalization_15/gamma:0 -- Total:8, Zeros: 0.0000%\n",
            "batch_normalization_15/beta:0 -- Total:8, Zeros: 0.0000%\n",
            "batch_normalization_15/moving_mean:0 -- Total:8, Zeros: 0.0000%\n",
            "batch_normalization_15/moving_variance:0 -- Total:8, Zeros: 0.0000%\n",
            "conv3d_8/kernel:0 -- Total:2880, Zeros: 28.9931%\n",
            "conv3d_8/bias:0 -- Total:8, Zeros: 0.0000%\n",
            "batch_normalization_16/gamma:0 -- Total:8, Zeros: 0.0000%\n",
            "batch_normalization_16/beta:0 -- Total:8, Zeros: 0.0000%\n",
            "batch_normalization_16/moving_mean:0 -- Total:8, Zeros: 0.0000%\n",
            "batch_normalization_16/moving_variance:0 -- Total:8, Zeros: 0.0000%\n",
            "conv3d_9/kernel:0 -- Total:3456, Zeros: 28.9931%\n",
            "conv3d_9/bias:0 -- Total:8, Zeros: 0.0000%\n",
            "batch_normalization_17/gamma:0 -- Total:8, Zeros: 0.0000%\n",
            "batch_normalization_17/beta:0 -- Total:8, Zeros: 0.0000%\n",
            "batch_normalization_17/moving_mean:0 -- Total:8, Zeros: 0.0000%\n",
            "batch_normalization_17/moving_variance:0 -- Total:8, Zeros: 0.0000%\n",
            "separable_conv2d_9/depthwise_kernel:0 -- Total:32400, Zeros: 0.0000%\n",
            "separable_conv2d_9/pointwise_kernel:0 -- Total:460800, Zeros: 28.9976%\n",
            "separable_conv2d_9/bias:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_18/gamma:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_18/beta:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_18/moving_mean:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_18/moving_variance:0 -- Total:128, Zeros: 0.0000%\n",
            "separable_conv2d_10/depthwise_kernel:0 -- Total:1152, Zeros: 0.0000%\n",
            "separable_conv2d_10/pointwise_kernel:0 -- Total:16384, Zeros: 28.9978%\n",
            "separable_conv2d_10/bias:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_19/gamma:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_19/beta:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_19/moving_mean:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_19/moving_variance:0 -- Total:128, Zeros: 0.0000%\n",
            "separable_conv2d_11/depthwise_kernel:0 -- Total:1152, Zeros: 0.0000%\n",
            "separable_conv2d_11/pointwise_kernel:0 -- Total:16384, Zeros: 28.9978%\n",
            "separable_conv2d_11/bias:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_20/gamma:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_20/beta:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_20/moving_mean:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_20/moving_variance:0 -- Total:128, Zeros: 0.0000%\n",
            "separable_conv2d_12/depthwise_kernel:0 -- Total:1152, Zeros: 0.0000%\n",
            "separable_conv2d_12/pointwise_kernel:0 -- Total:16384, Zeros: 28.9978%\n",
            "separable_conv2d_12/bias:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_21/gamma:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_21/beta:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_21/moving_mean:0 -- Total:128, Zeros: 0.0000%\n",
            "batch_normalization_21/moving_variance:0 -- Total:128, Zeros: 0.0000%\n",
            "fc3/kernel:0 -- Total:6144, Zeros: 29.0039%\n",
            "fc3/bias:0 -- Total:3, Zeros: 0.0000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKIRfZDn02rV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c822cd24-3ec0-4e07-eb10-2fa94b20a8c4"
      },
      "source": [
        "print('Saving pruned model to: ', \"Kochia_hyper3DNet_pruned.h5\")\n",
        "tf.keras.models.save_model(final_model, \"Kochia_hyper3DNet_pruned.h5\", \n",
        "                        include_optimizer=False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving pruned model to:  Kochia_hyper3DNet_pruned.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVT1KBWvEODg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "b3bc8b0f-3c00-483b-8129-8b7619718660"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from operator import truediv\n",
        "import h5py\n",
        "import pickle\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, cohen_kappa_score, confusion_matrix\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "import keras.backend as k\n",
        "import tensorflow as tf\n",
        "\n",
        "k.set_image_data_format('channels_last')\n",
        "k.set_learning_phase(1)\n",
        "\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "TRAIN PROPOSED NETWORK\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "windowSize = train_x.shape[1]\n",
        "classes = 3\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
        "cvoa = []\n",
        "cvaa = []\n",
        "cvka = []\n",
        "cvpre = []\n",
        "cvrec = []\n",
        "cvf1 = []\n",
        "\n",
        "\n",
        "def AA_andEachClassAccuracy(confusion_m):\n",
        "    list_diag = np.diag(confusion_m)\n",
        "    list_raw_sum = np.sum(confusion_m, axis=1)\n",
        "    each_ac = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
        "    average_acc = np.mean(each_ac)\n",
        "    return each_ac, average_acc\n",
        "\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "PREDICT AND CALCULATE METRICS\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "loaded_model = tf.keras.models.load_model(\"weights-hyper3dnet\" + 'WEED' + str(1) + \"-best_3layers_4filters.h5\")\n",
        "epochs = 8\n",
        "batch_size = 32;\n",
        "num_train_samples = train_x.shape[0]\n",
        "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
        "print(end_step)\n",
        "\n",
        "dataset = 'WEED'\n",
        "# Initialize\n",
        "confmatrices = np.zeros((10, int(classes), int(classes)))\n",
        "\n",
        "ntrain = 1\n",
        "for train, test in kfold.split(train_x, train_y):\n",
        "    ytest = tf.keras.utils.to_categorical(train_y[test]).astype(np.int32)\n",
        "\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    PRUNING\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    new_pruning_params = {\n",
        "          'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.10,\n",
        "                                                      final_sparsity=0.30,\n",
        "                                                      begin_step=0,\n",
        "                                                      end_step=end_step,\n",
        "                                                      frequency=100)\n",
        "    }\n",
        "\n",
        "    new_pruned_model = sparsity.prune_low_magnitude(loaded_model, **new_pruning_params)\n",
        "\n",
        "    new_pruned_model.load_weights(\"pruned-weights-hyper3dnet\" + dataset + str(ntrain) + \"-best_3layers_4filters.h5\")\n",
        "    ypred = new_pruned_model.predict(train_x[test])\n",
        "\n",
        "    sess = tf.Session()\n",
        "    with sess.as_default():\n",
        "        con_mat = tf.math.confusion_matrix(labels=np.argmax(ytest, axis=-1),\n",
        "                                           predictions=np.argmax(ypred, axis=-1)).numpy()\n",
        "\n",
        "    con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=3)\n",
        "    classes_list = list(range(0, int(classes)))\n",
        "    con_mat_df = pd.DataFrame(con_mat_norm, index=classes_list, columns=classes_list)\n",
        "\n",
        "    confmatrices[ntrain - 1, :, :] = con_mat_df.values\n",
        "\n",
        "    # Calculate metrics\n",
        "    oa = accuracy_score(np.argmax(ytest, axis=1), np.argmax(ypred, axis=-1))\n",
        "    confusion = confusion_matrix(np.argmax(ytest, axis=1), np.argmax(ypred, axis=-1))\n",
        "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
        "    kappa = cohen_kappa_score(np.argmax(ytest, axis=1), np.argmax(ypred, axis=-1))\n",
        "    prec, rec, f1, support = precision_recall_fscore_support(np.argmax(ytest, axis=1), np.argmax(ypred, axis=-1),\n",
        "                                                             average='macro')\n",
        "\n",
        "    # Add metrics to the list\n",
        "    cvoa.append(oa * 100)\n",
        "    cvaa.append(aa * 100)\n",
        "    cvka.append(kappa * 100)\n",
        "    cvpre.append(prec * 100)\n",
        "    cvrec.append(rec * 100)\n",
        "    cvf1.append(f1 * 100)\n",
        "\n",
        "    ntrain += 1\n",
        "\n",
        "file_name = \"classification_report_hyper3dnet_pruned\" + dataset + \".txt\"\n",
        "with open(file_name, 'w') as x_file:\n",
        "    x_file.write(\"Overall accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvoa)), float(np.std(cvoa))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"Average accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvaa)), float(np.std(cvaa))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"Kappa accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvka)), float(np.std(cvka))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"Precision accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvpre)), float(np.std(cvpre))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"Recall accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvrec)), float(np.std(cvrec))))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write(\"F1 accuracy%.3f%% (+/- %.3f%%)\" % (float(np.mean(cvf1)), float(np.std(cvf1))))\n",
        "\n",
        "# Calculate mean and std\n",
        "means = np.mean(confmatrices * 100, axis=0)\n",
        "stds = np.std(confmatrices * 100, axis=0)\n",
        "\n",
        "def plot_confusion_matrix(cm, cms, classescf,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classescf))\n",
        "    plt.xticks(tick_marks, classescf, rotation=45)\n",
        "    plt.yticks(tick_marks, classescf)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "\n",
        "            if (cm[i, j] == 100 or cm[i, j] == 0) and cms[i, j] == 0:\n",
        "                plt.text(j, i, '{0:.0f}'.format(cm[i, j]) + '\\n$\\pm$' + '{0:.0f}'.format(cms[i, j]),\n",
        "                         horizontalalignment=\"center\",\n",
        "                         verticalalignment=\"center\", fontsize=15,\n",
        "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "            else:\n",
        "                plt.text(j, i, '{0:.2f}'.format(cm[i, j]) + '\\n$\\pm$' + '{0:.2f}'.format(cms[i, j]),\n",
        "                         horizontalalignment=\"center\",\n",
        "                         verticalalignment=\"center\", fontsize=15,\n",
        "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "classes_list = list(range(0, int(3)))\n",
        "plt.figure()\n",
        "plot_confusion_matrix(means, stds, classescf=classes_list)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAEmCAYAAAAnRIjxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n09o8/AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}